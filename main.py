import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_ollama import OllamaLLM
from langchain.chains import RetrievalQA
import tempfile
import os
import shutil

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# Chroma –∫–∞–∫ –ª–æ–∫–∞–ª—å–Ω—ã–π –≤–µ–∫—Ç–æ—Ä–Ω—ã–π —Å—Ç–æ—Ä
vectorstore = Chroma(collection_name="constitution", embedding_function=embedding)

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ LLaMA3 —á–µ—Ä–µ–∑ Ollama
llm = OllamaLLM(model="llama3")

# Retrieval QA Chain
qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())

# Streamlit UI
st.title("üá∞üáø Kazakhstan Constitution AI Assistant")

# –ó–∞–≥—Ä—É–∑–∫–∞ PDF
uploaded_files = st.file_uploader("üìÑ Upload Constitution PDF(s)", type="pdf", accept_multiple_files=True)
if uploaded_files:
    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            temp_path = tmp_file.name
            shutil.copyfileobj(uploaded_file, tmp_file)

        loader = PyPDFLoader(temp_path)
        pages = loader.load_and_split()
        vectorstore.add_documents(pages)
        os.remove(temp_path)

    st.success("‚úÖ Files processed and added to vector store.")

# –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
question = st.text_input("üîé Ask your question:")
if question:
    answer = qa.run(question)
    st.markdown(f"**üí¨ Answer:** {answer}")
